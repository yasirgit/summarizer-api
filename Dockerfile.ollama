# Ollama Service Dockerfile
FROM ollama/ollama:latest

# Build arguments
ARG BUILD_DATE
ARG VERSION
ARG REVISION
ARG DOCKER_NAMESPACE=summarizer

# Create a directory for the model
RUN mkdir -p /root/.ollama

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
    CMD curl -f http://localhost:11434/api/tags || exit 1

# Expose port
EXPOSE 11434

# Add labels for better image metadata
LABEL org.opencontainers.image.created=${BUILD_DATE} \
      org.opencontainers.image.version=${VERSION} \
      org.opencontainers.image.revision=${REVISION} \
      org.opencontainers.image.title="Summarizer Ollama" \
      org.opencontainers.image.description="Ollama LLM service with pre-loaded gemma3:1b model" \
      org.opencontainers.image.vendor="Summarizer API Project" \
      org.opencontainers.image.source="https://github.com/user/summarizer-api" \
      org.opencontainers.image.url="https://hub.docker.com/r/${DOCKER_NAMESPACE}/ollama" \
      org.opencontainers.image.documentation="https://github.com/user/summarizer-api" \
      org.opencontainers.image.licenses="MIT"

# Start Ollama directly without shell dependencies
ENTRYPOINT ["/bin/ollama", "serve"]
# Test Suite Documentation

## Overview

This test suite provides comprehensive coverage for the Summarizer API with proper test isolation, mock services, and coverage for all advanced features.

## Test Structure

### ğŸ—ï¸ Test Infrastructure (`conftest.py`)
- **Test App Setup**: Isolated FastAPI application with test database
- **Mock Services**: Redis, RQ, Ollama client, and content extractor mocks  
- **Test Database**: SQLite in-memory database for fast, isolated tests
- **Fixtures**: HTML content, sample documents, and test data

### ğŸ”§ Core API Tests (`test_api_core.py`)
- âœ… **POST /documents/** returns 202 with correct shape
- âœ… **GET /documents/{uuid}/** returns resource data
- âœ… **Summary initially null** until processing completes
- âœ… **Input validation** for required fields and URL format
- âœ… **Health endpoints** (`/healthz`, `/readyz`)
- âœ… **API versioning** under `/api/v1/`

### ğŸ“Š Progress Tests (`test_progress.py`)
- âœ… **Pipeline stages**: `0.0 â†’ 0.2 â†’ 0.4 â†’ 0.9 â†’ 1.0`
- âœ… **Progress increases monotonically** through all stages
- âœ… **Failed stages preserve progress** at failure point
- âœ… **Idempotent processing** skips completed documents
- âœ… **Redis progress tracking** integration

### ğŸ” Extraction Tests (`test_extraction.py`)
- âœ… **HTML fixtures**: Simple, complex, and minimal content
- âœ… **Content cleaning** with whitespace normalization
- âœ… **Error handling**: HTTP errors, network failures, timeouts
- âœ… **Security validation**: SSRF protection for private IPs and file URLs
- âœ… **Retry mechanism** with exponential backoff
- âœ… **Fallback to readability** when trafilatura fails

### ğŸ”„ Uniqueness Tests (`test_uniqueness_and_resummarize.py`)
- âœ… **409 Conflict** for name collisions on different documents
- âœ… **409 Conflict** for URL collisions on different documents  
- âœ… **Exact name+URL match** re-triggers summarization
- âœ… **Re-summarization** clears previous state (summary, errors, progress)
- âœ… **Multiple resummarization cycles** support
- âœ… **Unicode and case sensitivity** handling

### âš¡ Concurrency Tests (`test_concurrency.py`)
- âœ… **Parallel POSTs** with same inputs create no duplicate rows
- âœ… **Queue management** prevents duplicate jobs
- âœ… **Race condition handling** in document creation
- âœ… **Database transaction isolation** under concurrent load
- âœ… **Mixed concurrent operations** (GET/POST combinations)
- âœ… **Memory stability** under high concurrent load

### ğŸ“ Summarizer Tests (`test_summarizer_stub.py`)
- âœ… **â‰¤1500 character enforcement** with automatic trimming
- âœ… **Sentence boundary trimming** preserves readability
- âœ… **Word boundary fallback** when no sentence endings found
- âœ… **Unicode character counting** accuracy
- âœ… **Quality requirements** (deterministic, no markdown, key facts)
- âœ… **Integration with pipeline** length validation

## Mock Services

### ğŸ—„ï¸ Database
```python
# SQLite in-memory for fast, isolated tests
TEST_DATABASE_URL = "sqlite+aiosqlite:///:memory:"
```

### ğŸ”´ Redis
```python
# Mock Redis with basic operations
mock_redis.get.return_value = None
mock_redis.setex.return_value = True
```

### ğŸ¤– Ollama Client
```python
# Mock summarization with length-controlled output
mock_client.summarize.return_value = "Test summary content."
```

### ğŸ•·ï¸ Content Extractor
```python
# Mock web content extraction
mock_extractor.extract_content_from_url.return_value = "Extracted content"
```

## Running Tests

### Quick Start
```bash
# Run all tests
./scripts/run_tests.sh

# Or manually
pytest tests/ -v
```

### Specific Test Categories
```bash
# Core API functionality
pytest tests/test_api_core.py -v

# Progress tracking
pytest tests/test_progress.py -v

# Content extraction  
pytest tests/test_extraction.py -v

# Uniqueness and re-summarization
pytest tests/test_uniqueness_and_resummarize.py -v

# Concurrency handling
pytest tests/test_concurrency.py -v

# Summarizer validation
pytest tests/test_summarizer_stub.py -v
```

### With Coverage
```bash
pytest tests/ --cov=app --cov-report=html
# View: htmlcov/index.html
```

## Test Fixtures

### HTML Content
- **Simple**: Basic HTML with clear content structure
- **Complex**: Real-world HTML with navigation, sidebars, etc.
- **Minimal**: Edge case HTML with little extractable content

### Test Data
- **Sample documents** with various states (PENDING, SUCCESS, FAILED)
- **Long text content** for testing summarization limits
- **Unicode content** for internationalization testing

## Integration Points

### Database Operations
- âœ… Document CRUD operations
- âœ… Status and progress updates  
- âœ… Unique constraint handling
- âœ… Transaction isolation

### External Services
- âœ… HTTP content fetching (mocked)
- âœ… Redis job queuing (mocked)
- âœ… Ollama summarization (mocked)
- âœ… Background task processing

### Business Logic
- âœ… Pipeline stage progression
- âœ… Error handling and recovery
- âœ… Idempotency enforcement
- âœ… Concurrent request handling

## Test Environment

### Configuration
```python
class TestSettings(Settings):
    database_url: str = "sqlite+aiosqlite:///:memory:"
    redis_url: str = "redis://localhost:6379/15" 
    log_level: str = "DEBUG"
```

### Dependencies
- `pytest` - Test framework
- `pytest-asyncio` - Async test support
- `httpx` - HTTP client for API testing
- `pytest-cov` - Coverage reporting

## Coverage Goals

- **Overall Coverage**: â‰¥80%
- **Core API**: â‰¥95%
- **Business Logic**: â‰¥90%
- **Error Handling**: â‰¥85%

## Best Practices

### Test Isolation
- Each test uses fresh database
- Mocks reset between tests
- No shared state between tests

### Async Testing
```python
@pytest.mark.asyncio
async def test_async_operation():
    # Proper async test pattern
    result = await async_operation()
    assert result is not None
```

### Mock Usage
```python
# Comprehensive mocking
@pytest.fixture
def mock_service(mocker):
    return mocker.patch('app.service.external_call')
```

### Error Testing
```python
# Test both success and failure paths
with pytest.raises(ExpectedError):
    await operation_that_should_fail()
```

## Maintenance

### Adding New Tests
1. Follow existing patterns in test files
2. Use appropriate fixtures from `conftest.py`
3. Include both success and failure scenarios
4. Add concurrency tests for new endpoints

### Updating Mocks
1. Keep mocks in sync with real service interfaces
2. Update fixtures when data models change
3. Verify mock behavior matches real services

### Performance
- Tests should complete in <30 seconds total
- Individual tests should be <1 second
- Use `@pytest.mark.slow` for longer tests
